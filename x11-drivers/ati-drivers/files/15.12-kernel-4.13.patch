--- a/common/lib/modules/fglrx/build_mod/firegl_public.c	2015-12-19 00:47:41.000000000 +0600
+++ b/common/lib/modules/fglrx/build_mod/firegl_public.c	2017-10-07 23:29:42.600868957 +0600
@@ -21,6 +21,8 @@
 !!! since it requires changes to linux/init/main.c.
 #endif /* !MODULE */
 
+#include <linux/preempt.h>
+
 // ============================================================
 #include <linux/version.h>
 
@@ -134,7 +136,6 @@
 #include <asm/mman.h>
 #include <asm/uaccess.h>
 #include <asm/processor.h>
-#include <asm/tlbflush.h> // for flush_tlb_page
 #include <asm/cpufeature.h>
 #ifdef CONFIG_MTRR
 #include <asm/mtrr.h>
@@ -203,6 +204,10 @@
 #include <asm/fpu/internal.h>
 #endif
 #endif
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(4,13,0)
+#include <linux/mm.h>
+#include <linux/sched/signal.h>
+#endif
 
 #include "firegl_public.h"
 #include "kcl_osconfig.h"
@@ -257,6 +262,26 @@
 #define WRITE_CR4(x)    write_cr4(x)
 #endif
 
+#define __flush_tlb_one(addr) asm volatile("invlpg (%0)" ::"r" (addr) : "memory")
+#define __flush_tlb() native_write_cr3(native_read_cr3())
+
+static inline void __flush_tlb_all(void)
+{
+        if (cpu_has_pge)
+        {
+                unsigned long flags, cr4;
+                raw_local_irq_save(flags);
+                cr4 = native_read_cr4();
+                native_write_cr4(cr4 & ~X86_CR4_PGE);
+                native_write_cr4(cr4);
+                raw_local_irq_restore(flags);
+        }
+        else
+        {
+                __flush_tlb();
+        }
+}
+
 // ============================================================
 /* globals */
 
@@ -553,6 +578,8 @@
 }
 
 #else
+#include <linux/seq_file.h>
+
 #define READ_PROC_WRAP(func)                                            \
 static int func##_wrap(struct seq_file *m, void* data)                  \
 {                                                                       \
@@ -630,6 +657,9 @@
     *eof = 1;
 
     len = snprintf(buf, request, "%d\n", major);
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(4,3,0)
+    seq_printf(m, "%d\n", major);
+    len = 0;
 #else
     len = seq_printf(m, "%d\n", major);
 #endif
@@ -3220,7 +3250,15 @@
     int ret;
 
     down_read(&current->mm->mmap_sem);
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(4,13,0)
+    ret = get_user_pages_remote(current, current->mm, vaddr, page_cnt, 1, (struct page **)page_list, NULL, NULL);
+#elif LINUX_VERSION_CODE >= KERNEL_VERSION(4,9,0)
+    ret = get_user_pages_remote(current, current->mm, vaddr, page_cnt, 1, (struct page **)page_list, NULL);
+#elif LINUX_VERSION_CODE >= KERNEL_VERSION(4,6,0)
+    ret = get_user_pages_remote(current, current->mm, vaddr, page_cnt, 1, 0, (struct page **)page_list, NULL);
+#else    
     ret = get_user_pages(current, current->mm, vaddr, page_cnt, 1, 0, (struct page **)page_list, NULL);
+#endif    
     up_read(&current->mm->mmap_sem);
 
     return ret;
@@ -3238,7 +3276,15 @@
     int ret;
 
     down_read(&current->mm->mmap_sem);
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(4,13,0)
+    ret = get_user_pages_remote(current, current->mm, vaddr, page_cnt, 0, (struct page **)page_list, NULL, NULL);
+#elif LINUX_VERSION_CODE >= KERNEL_VERSION(4,9,0)
+    ret = get_user_pages_remote(current, current->mm, vaddr, page_cnt, 0, (struct page **)page_list, NULL);
+#elif LINUX_VERSION_CODE >= KERNEL_VERSION(4,6,0)
+    ret = get_user_pages_remote(current, current->mm, vaddr, page_cnt, 0, 0, (struct page **)page_list, NULL);
+#else    
     ret = get_user_pages(current, current->mm, vaddr, page_cnt, 0, 0, (struct page **)page_list, NULL);
+#endif    
     up_read(&current->mm->mmap_sem);
 
     return ret;
@@ -3249,7 +3295,11 @@
     unsigned int i;
     for (i=0; i<page_cnt; i++)
     {
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(4,6,0)
+        put_page((struct page*)page_list[i]);
+#else        
         page_cache_release((struct page*)page_list[i]);
+#endif        
     }
 }
 
@@ -3424,7 +3474,11 @@
 int ATI_API_CALL KCL_MEM_MTRR_AddRegionWc(unsigned long base, unsigned long size)
 {
 #ifdef CONFIG_MTRR
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(4,3,0)
+    return arch_phys_wc_add(base, size);
+#else
     return mtrr_add(base, size, MTRR_TYPE_WRCOMB, 1);
+#endif
 #else /* !CONFIG_MTRR */
     return -EPERM;
 #endif /* !CONFIG_MTRR */
@@ -3433,7 +3487,12 @@
 int ATI_API_CALL KCL_MEM_MTRR_DeleteRegion(int reg, unsigned long base, unsigned long size)
 {
 #ifdef CONFIG_MTRR
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(4,3,0)
+    arch_phys_wc_del(reg);
+    return reg;
+#else
     return mtrr_del(reg, base, size);
+#endif
 #else /* !CONFIG_MTRR */
     return -EPERM;
 #endif /* !CONFIG_MTRR */
@@ -3596,7 +3655,9 @@
     unsigned long vma_offset;
     unsigned long pte_linear;
     mem_map_t* pMmPage;
-#if LINUX_VERSION_CODE >= KERNEL_VERSION(2,6,26)
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(4,13,0)
+    unsigned long address = (unsigned long) (vmf->address);
+#elif LINUX_VERSION_CODE >= KERNEL_VERSION(2,6,26)
     unsigned long address = (unsigned long) (vmf->virtual_address);
 #endif
 
@@ -3671,7 +3732,9 @@
 {
     unsigned long kaddr;
     mem_map_t* pMmPage;
-#if LINUX_VERSION_CODE >= KERNEL_VERSION(2,6,26)
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(4,13,0)
+    unsigned long address = (unsigned long) (vmf->address);
+#elif LINUX_VERSION_CODE >= KERNEL_VERSION(2,6,26)
     unsigned long address = (unsigned long) (vmf->virtual_address);
 #endif
 
@@ -3716,7 +3779,9 @@
 {
     unsigned long kaddr;
     mem_map_t* pMmPage;
-#if LINUX_VERSION_CODE >= KERNEL_VERSION(2,6,26)
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(4,13,0)
+    unsigned long address = (unsigned long) (vmf->address);
+#elif LINUX_VERSION_CODE >= KERNEL_VERSION(2,6,26)
     unsigned long address = (unsigned long) (vmf->virtual_address);
 #endif
 
@@ -3779,7 +3844,9 @@
     mem_map_t* pMmPage;
     struct firegl_pcie_mem* pciemem;
     unsigned long* pagelist;
-#if LINUX_VERSION_CODE >= KERNEL_VERSION(2,6,26)
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(4,13,0)
+    unsigned long address = (unsigned long) (vmf->address);
+#elif LINUX_VERSION_CODE >= KERNEL_VERSION(2,6,26)
     unsigned long address = (unsigned long) (vmf->virtual_address);
 #endif
     
@@ -3841,7 +3908,9 @@
 
     unsigned long offset;
     struct page *page;
-#if LINUX_VERSION_CODE >= KERNEL_VERSION(2,6,26)
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(4,13,0)
+    unsigned long address = (unsigned long) (vmf->address);
+#elif LINUX_VERSION_CODE >= KERNEL_VERSION(2,6,26)
     unsigned long address = (unsigned long) (vmf->virtual_address);
 #endif
 
@@ -4135,7 +4204,38 @@
 }
 
 #else
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(4,13,0)
+#define TRACE_FAULT(_f, _v,_a)                                          \
+   int  ret;                                                            \
+   KCL_DEBUG_TRACEIN(FN_DRM_NOPAGE, (unsigned long)_a->address, NULL); \
+   ret = _f(_v,_a);                                                     \
+   KCL_DEBUG_TRACEOUT(FN_DRM_NOPAGE, ret, NULL);                                \
+   return ret;
+#endif
 
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(4,13,0)
+
+static int ip_vm_fault(struct vm_fault *vmf) {
+    TRACE_FAULT(do_vm_fault, vmf->vma, vmf);
+}
+static int ip_vm_shm_fault(struct vm_fault *vmf) {
+    TRACE_FAULT(do_vm_shm_fault, vmf->vma, vmf);
+}
+static int ip_vm_dma_fault(struct vm_fault *vmf) {
+    TRACE_FAULT(do_vm_dma_fault, vmf->vma, vmf);
+}
+static int ip_vm_kmap_fault(struct vm_fault *vmf) {
+    TRACE_FAULT(do_vm_kmap_fault, vmf->vma, vmf);
+}
+static int ip_vm_pcie_fault(struct vm_fault *vmf) {
+    TRACE_FAULT(do_vm_pcie_fault, vmf->vma, vmf);
+}
+static int ip_vm_gart_fault(struct vm_fault *vmf) {
+    TRACE_FAULT(do_vm_gart_fault, vmf->vma, vmf);
+}
+
+#else /* LINUX_VERSION_CODE >= KERNEL_VERSION(4,13,0) */   
+#else
 #define TRACE_FAULT(_f, _v,_a)                                          \
    int  ret;                                                            \
    KCL_DEBUG_TRACEIN(FN_DRM_NOPAGE, (unsigned long)_a->virtual_address, NULL); \
@@ -4518,7 +4618,11 @@
     write_cr0(cr0);
     wbinvd();
 
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(4,7,0)
+    if (boot_cpu_has(X86_FEATURE_PGE))
+#else    
     if (cpu_has_pge)
+#endif        
     {
         cr4 = READ_CR4();
         WRITE_CR4(cr4 & ~X86_CR4_PGE);
@@ -4532,7 +4636,11 @@
     wbinvd();
     __flush_tlb();
     write_cr0(cr0 & 0xbfffffff);
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(4,7,0)
+    if (boot_cpu_has(X86_FEATURE_PGE))
+#else    
     if (cpu_has_pge)
+#endif        
     {
         WRITE_CR4(cr4);
     }
@@ -4559,7 +4667,11 @@
     write_cr0(cr0);
     wbinvd();
 
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(4,7,0)
+    if (boot_cpu_has(X86_FEATURE_PGE))
+#else    
     if (cpu_has_pge)
+#endif        
     {
         cr4 = READ_CR4();
         WRITE_CR4(cr4 & ~X86_CR4_PGE);
@@ -4572,7 +4684,11 @@
     wbinvd();
     __flush_tlb();
     write_cr0(cr0 & 0xbfffffff);
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(4,7,0)
+    if (boot_cpu_has(X86_FEATURE_PGE))
+#else    
     if (cpu_has_pge)
+#endif        
     {
         WRITE_CR4(cr4);
     }
@@ -5010,7 +5126,9 @@
 unsigned long ATI_API_CALL KAS_GetExecutionLevel(void)
 {
     unsigned long ret;
+    preempt_disable();
     ret = kas_GetExecutionLevel();
+    preempt_enable();
     return ret;
 }
 
@@ -5035,8 +5153,10 @@
     KCL_DEBUG5(FN_FIREGL_KAS,"0x%08X, 0x%08X\n", ih_routine, ih_context);
 
     //Prevent simultaneous entry on some SMP systems.
+    preempt_disable();
     if (test_and_set_bit(0, (void *)&(kasContext.in_interrupts[smp_processor_id()])))
     {
+    	preempt_enable();
         KCL_DEBUG1(FN_FIREGL_KAS, "The processor is handling the interrupt\n");
         return IRQ_NONE;
     }
@@ -5049,9 +5169,9 @@
 
     kasSetExecutionLevel(orig_level);
     spin_unlock(&kasContext.lock_ih); 
-
     clear_bit(0, (void *)&(kasContext.in_interrupts[smp_processor_id()]));
     KCL_DEBUG5(FN_FIREGL_KAS,"%d\n", ret);
+    preempt_enable();
 
     return ret;
 }
@@ -5269,6 +5389,7 @@
 
     KCL_DEBUG5(FN_FIREGL_KAS,"0x%08X\n", hSpinLock);
 
+    preempt_disable();
     spin_lock_info.routine_type = spinlock_obj->routine_type;
     spin_lock_info.plock = &(spinlock_obj->lock);
 
@@ -5276,6 +5397,7 @@
 
     spinlock_obj->acquire_type = spin_lock_info.acquire_type;
     spinlock_obj->flags = spin_lock_info.flags;
+    preempt_enable();
 
     KCL_DEBUG5(FN_FIREGL_KAS,"%d\n", ret);
     return ret;
@@ -6047,6 +6169,8 @@
 
     KCL_DEBUG5(FN_FIREGL_KAS,"0x%08X, 0x%08X, 0x%08X\n", hListHead, hListEntry, phPrevEntry);
 
+    preempt_disable();
+
     /* Protect the operation with spinlock */
     spin_lock_info.routine_type = listhead_obj->routine_type;
     spin_lock_info.plock = &(listhead_obj->lock);
@@ -6054,6 +6178,7 @@
     if (!kas_spin_lock(&spin_lock_info))
     {
         KCL_DEBUG_ERROR("Unable to grab list spinlock\n");
+	preempt_enable();
         return 0; /* No spinlock - no operation */
     }
 
@@ -6078,6 +6203,7 @@
     spin_unlock_info.flags = spin_lock_info.flags;
 
     ret = kas_spin_unlock(&spin_unlock_info);
+    preempt_enable();
     KCL_DEBUG5(FN_FIREGL_KAS,"%d", ret);
     return ret;
 }
@@ -6166,8 +6292,10 @@
     spin_lock_info.routine_type = listhead_obj->routine_type;
     spin_lock_info.plock = &(listhead_obj->lock);
 
+    preempt_disable();
     if (!kas_spin_lock(&spin_lock_info))
     {
+        preempt_enable();
         KCL_DEBUG_ERROR("Unable to grab list spinlock");
         return 0; /* No spinlock - no operation */
     }
@@ -6191,6 +6319,7 @@
     spin_unlock_info.flags = spin_lock_info.flags;
 
     ret = kas_spin_unlock(&spin_unlock_info);
+    preempt_enable();
     KCL_DEBUG5(FN_FIREGL_KAS,"%d", ret);
     return ret;
 }
@@ -6450,12 +6579,19 @@
    struct fpu *fpu = &tsk->thread.fpu;
 
    if(static_cpu_has(X86_FEATURE_XSAVE)) {
-#if LINUX_VERSION_CODE < KERNEL_VERSION(4,2,0)
-      fpu_xsave(fpu);
-      if (!(fpu->state->xsave.xsave_hdr.xstate_bv & XSTATE_FP))
-#else
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(4,4,0)
+	  copy_xregs_to_kernel(&fpu->state.xsave);
+      if (!(fpu->state.xsave.header.xfeatures & XFEATURE_MASK_FP))
+#elif LINUX_VERSION_CODE >= KERNEL_VERSION(4,2,0)
 	  copy_xregs_to_kernel(&fpu->state.xsave);
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(4,4,0)
+      if (!(fpu->state.xsave.header.xfeatures & XFEATURE_MASK_FP))
+#else
       if (!(fpu->state.xsave.header.xfeatures & XSTATE_FP))
+#else
+      fpu_xsave(fpu);
+      if (!(fpu->state->xsave.xsave_hdr.xstate_bv & XSTATE_FP))          
+#endif
 #endif
          return 1;
    } else if (static_cpu_has(X86_FEATURE_FXSR)) {
--- a/common/lib/modules/fglrx/build_mod/firegl_public.h	2015-12-19 00:47:41.000000000 +0600
+++ b/common/lib/modules/fglrx/build_mod/firegl_public.h	2017-10-07 23:32:50.692883977 +0600
@@ -650,9 +650,15 @@
 #define cpu_has_pat  test_bit(X86_FEATURE_PAT, (void *) &boot_cpu_data.x86_capability)
 #endif
 
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(4,7,0)
+#ifndef boot_cpu_has(X86_FEATURE_PGE)
+#define boot_cpu_has(X86_FEATURE_PGE) test_bit(X86_FEATURE_PGE, &boot_cpu_data.x86_capability)
+#endif
+#else
 #ifndef cpu_has_pge
 #define cpu_has_pge test_bit(X86_FEATURE_PGE, &boot_cpu_data.x86_capability)
 #endif
+#endif
 
 /* 2.6.29 defines pgprot_writecombine as a macro which resolves to a
  * GPL-only function with the same name. So we always use our own
--- a/common/lib/modules/fglrx/build_mod/kcl_acpi.c	2015-12-19 00:47:41.000000000 +0600
+++ b/common/lib/modules/fglrx/build_mod/kcl_acpi.c	2017-10-07 21:23:03.319262131 +0600
@@ -359,7 +359,10 @@
 {
     struct acpi_table_header *hdr;
     acpi_size tbl_size ;
-#if LINUX_VERSION_CODE >= KERNEL_VERSION(3,6,3)    
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(4,13,0)
+    tbl_size = hdr->length;
+    if (!ACPI_SUCCESS(acpi_get_table("VFCT", 1, &hdr)))
+#elif LINUX_VERSION_CODE >= KERNEL_VERSION(3,6,3)     
     if (!ACPI_SUCCESS(acpi_get_table_with_size("VFCT", 1, &hdr, &tbl_size)))
 #else
     tbl_size = 0x7fffffff;
@@ -868,7 +871,7 @@
 #elif LINUX_VERSION_CODE >= KERNEL_VERSION(3,17,0)
     if(pdev)
     {
-#if (UTS_UBUNTU_RELEASE_ABI < 0 && LINUX_VERSION_CODE < KERNEL_VERSION(4,1,3)) || (UTS_UBUNTU_RELEASE_ABI >= 0 && UTS_UBUNTU_RELEASE_ABI < 26 && LINUX_VERSION_CODE <= KERNEL_VERSION(3,19,8))
+#if 0 && (UTS_UBUNTU_RELEASE_ABI < 0 && LINUX_VERSION_CODE < KERNEL_VERSION(4,1,3)) || (UTS_UBUNTU_RELEASE_ABI >= 0 && UTS_UBUNTU_RELEASE_ABI < 26 && LINUX_VERSION_CODE <= KERNEL_VERSION(3,19,8))
        pci_ignore_hotplug(pdev);
 #else
        pdev->ignore_hotplug = 1;
@@ -1029,7 +1032,10 @@
         return KCL_ACPI_ERROR; 
     }
 
-#if LINUX_VERSION_CODE >= KERNEL_VERSION(3,6,3)    
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(4,13,0)
+    tbl_size = hdr->length;
+    if (!ACPI_SUCCESS(acpi_get_table(id, 0, &hdr)))
+#elif LINUX_VERSION_CODE >= KERNEL_VERSION(3,6,3) 
     if (!ACPI_SUCCESS(acpi_get_table_with_size(id, 0, &hdr, &tbl_size)))
 #else
     tbl_size = 0x7fffffff;
--- a/common/lib/modules/fglrx/build_mod/kcl.c	2015-12-19 00:47:41.000000000 +0600
+++ b/common/lib/modules/fglrx/build_mod/kcl.c	2017-10-07 21:30:39.364298548 +0600
@@ -30,6 +30,11 @@
 #include <linux/slab.h>
 #include <linux/pci.h>
 
+#include <linux/version.h>
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(4,13,0)
+#include <linux/sched/signal.h>
+#endif
+
 #define SUSPEND_CONSOLE  (MAX_NR_CONSOLES-1)
 
 /** \brief Send signal to a specified pid
@@ -128,4 +133,4 @@
     pFirmware->fw = NULL;
     
     return 0;
-}
\No new string at the end of file
+}
